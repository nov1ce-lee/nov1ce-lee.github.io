import{_ as o,c as p,e as l,b as d,w as i,r as c,o as h,a as e,d as s}from"./app-B6rSt3_j.js";const m={};function k(g,a){const r=c("Tabs");return h(),p("div",null,[a[4]||(a[4]=l('<blockquote><p>在这篇文章中，我将基于<code>Ollama</code>，在<code>Windows</code>和<code>Ubuntu</code>系统中快速部署<code>DeepSeek</code></p><p>当然，要想使用响应更快速、效果更优秀的模型，还是需要更好的<code>GPU</code>来支持的</p></blockquote><h2 id="ollama的下载与安装" tabindex="-1"><a class="header-anchor" href="#ollama的下载与安装"><span>Ollama的下载与安装</span></a></h2><blockquote><p>Ollama是一个轻量级的工具，可以帮助你在本地快速部署和运行大语言模型</p></blockquote>',3)),d(r,{id:"16",data:[{id:"Windows"},{id:"Ubuntu"}]},{title0:i(({value:t,isActive:n})=>a[0]||(a[0]=[s("Windows",-1)])),title1:i(({value:t,isActive:n})=>a[1]||(a[1]=[s("Ubuntu",-1)])),tab0:i(({value:t,isActive:n})=>a[2]||(a[2]=[e("p",null,[s("点击进入"),e("code",null,"Ollama"),s("官网下载Ollama "),e("a",{href:"https://www.ollama.com/download/windows",target:"_blank",rel:"noopener noreferrer"},"Download Ollama")],-1)])),tab1:i(({value:t,isActive:n})=>a[3]||(a[3]=[e("div",{class:"language- line-numbers-mode","data-highlighter":"shiki","data-ext":"",style:{"--shiki-light":"#393a34","--shiki-dark":"#dbd7caee","--shiki-light-bg":"#ffffff","--shiki-dark-bg":"#121212"}},[e("pre",{class:"shiki shiki-themes vitesse-light vitesse-dark vp-code"},[e("code",{class:"language-"},[e("span",{class:"line"},[e("span",null,"# 输入如下命令安装ollama")]),s(`
`),e("span",{class:"line"},[e("span",null,"curl -fsSL https://ollama.com/install.sh | sh")])])]),e("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1)])),_:1}),a[5]||(a[5]=l(`<h2 id="deepseek模型的下载运行" tabindex="-1"><a class="header-anchor" href="#deepseek模型的下载运行"><span>DeepSeek模型的下载运行</span></a></h2><p>Ollama安装完成后打开终端，根据需要选择安装模型 <a href="https://www.ollama.com/library/deepseek-r1" target="_blank" rel="noopener noreferrer">DeepSeek模型列表</a></p><figure><img src="https://obsidian-pic-1326566629.cos.ap-shanghai.myqcloud.com/20250727215634886.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>在终端输入如下命令即可完成安装并运行</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># Default 7B model (4.7GB - ideal for consumer GPUs)</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> run</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> deepseek-r1</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># Larger 70B model (requires 24GB+ VRAM)</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> run</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> deepseek-r1:70b</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># Actual DeepSeek-R1 (requires 336GB+ VRAM for 4-bit quantization) </span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">ollama</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> run</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> deepseek-r1:671b</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">提示</p><p>下载速度很快，若下载速度降低可以取消后再次输入命令，有断点续传功能，速度可以再次跑满</p></div><h2 id="deepseek-r1-效果" tabindex="-1"><a class="header-anchor" href="#deepseek-r1-效果"><span>DeepSeek-r1 效果</span></a></h2><figure><img src="https://obsidian-pic-1326566629.cos.ap-shanghai.myqcloud.com/20250727215623113.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="导航" tabindex="-1"><a class="header-anchor" href="#导航"><span>导航</span></a></h2><p><strong>DeepSeek</strong> <a href="https://github.com/deepseek-ai" target="_blank" rel="noopener noreferrer">Github</a></p><p><strong>DeepSeek配置要求</strong> <a href="https://ngabbs.com/read.php?tid=43169616&amp;rand=73" target="_blank" rel="noopener noreferrer">PC端 完全本地部署deepseek的配置要求</a></p><p><strong>Open WebUI</strong> <a href="https://github.com/open-webui/open-webui" target="_blank" rel="noopener noreferrer">Github</a></p>`,12))])}const b=o(m,[["render",k]]),v=JSON.parse('{"path":"/blog/deepseek/","title":"基于Ollama快速本地部署DeepSeek","lang":"zh-CN","frontmatter":{"title":"基于Ollama快速本地部署DeepSeek","tags":["DeepSeek","Ollama","Windows","Ubuntu"],"createTime":"2025/01/31 15:57:23","permalink":"/blog/deepseek/","description":"在这篇文章中，我将基于Ollama，在Windows和Ubuntu系统中快速部署DeepSeek 当然，要想使用响应更快速、效果更优秀的模型，还是需要更好的GPU来支持的 Ollama的下载与安装 Ollama是一个轻量级的工具，可以帮助你在本地快速部署和运行大语言模型 DeepSeek模型的下载运行 Ollama安装完成后打开终端，根据需要选择安装模...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"基于Ollama快速本地部署DeepSeek\\",\\"image\\":[\\"https://obsidian-pic-1326566629.cos.ap-shanghai.myqcloud.com/20250727215634886.png\\",\\"https://obsidian-pic-1326566629.cos.ap-shanghai.myqcloud.com/20250727215623113.png\\"],\\"dateModified\\":\\"2025-12-11T16:51:13.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://nov1ce-lee.github.io/blog/deepseek/"}],["meta",{"property":"og:site_name","content":"novice.log"}],["meta",{"property":"og:title","content":"基于Ollama快速本地部署DeepSeek"}],["meta",{"property":"og:description","content":"在这篇文章中，我将基于Ollama，在Windows和Ubuntu系统中快速部署DeepSeek 当然，要想使用响应更快速、效果更优秀的模型，还是需要更好的GPU来支持的 Ollama的下载与安装 Ollama是一个轻量级的工具，可以帮助你在本地快速部署和运行大语言模型 DeepSeek模型的下载运行 Ollama安装完成后打开终端，根据需要选择安装模..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://obsidian-pic-1326566629.cos.ap-shanghai.myqcloud.com/20250727215634886.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-11T16:51:13.000Z"}],["meta",{"property":"article:tag","content":"Ubuntu"}],["meta",{"property":"article:tag","content":"Windows"}],["meta",{"property":"article:tag","content":"Ollama"}],["meta",{"property":"article:tag","content":"DeepSeek"}],["meta",{"property":"article:modified_time","content":"2025-12-11T16:51:13.000Z"}]]},"readingTime":{"minutes":1.11,"words":333},"git":{"createdTime":1765471873000,"updatedTime":1765471873000,"contributors":[{"name":"nov1ce","username":"nov1ce","email":"289836737@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/nov1ce?v=4","url":"https://github.com/nov1ce"}]},"autoDesc":true,"filePathRelative":"人工智能/deepseek.md","headers":[],"categoryList":[{"id":"f068f0","sort":10003,"name":"人工智能"}]}');export{b as comp,v as data};

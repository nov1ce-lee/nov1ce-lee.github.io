import{_ as h,c as p,a as l,d as i,e as a,b as d,w as r,t as n,r as k,o}from"./app-BDKILcas.js";const u={};function c(e,s){const t=k("VPLink");return o(),p("div",null,[s[13]||(s[13]=l('<h2 id="目的" tabindex="-1"><a class="header-anchor" href="#目的"><span>目的</span></a></h2><p>使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变</p><h2 id="启动llama-factory" tabindex="-1"><a class="header-anchor" href="#启动llama-factory"><span>启动LLaMA Factory</span></a></h2><ul><li>进入 LLaMA-Factory 目录下</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">cd</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> LLaMA-Factory</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>使用此命令开启llamafactory，若界面关闭模型训练便会终止</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webui</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>若希望后台一直训练，则使用nohup 调起即可</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">nohup</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webui</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> &amp;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>关闭则 使用kill 指定进程名即可</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">kill</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -9</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>若希望在使用llamafactory 使用指定显卡，那么使用这行命令：</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">CUDA_VISIBLE_DEVICES</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">6</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webui</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="模块介绍" tabindex="-1"><a class="header-anchor" href="#模块介绍"><span>模块介绍</span></a></h2>',14)),i("table",null,[s[10]||(s[10]=i("thead",null,[i("tr",null,[i("th",null,"modules"),i("th",null,"function"),i("th",null,"note")])],-1)),i("tbody",null,[s[3]||(s[3]=i("tr",null,[i("td",null,"模型路径"),i("td",null,[a("支持 "),i("code",null,"huggingface"),a(" 在线路径，或者本地的模型路径")]),i("td",null,[a("注意是绝对路径，"),i("code",null,".config"),a(" 文件上一层")])],-1)),s[4]||(s[4]=i("tr",null,[i("td",null,"微调方法"),i("td",null,[a("支持 "),i("code",null,"lora / freeze / full"),a(" 方法")]),i("td",null,[i("code",null,"lora(Low-Rank Adaptation)"),a("指通过在模型的某些层中添加"),i("code",null,"低秩矩阵"),a("来实现微调"),i("br"),a(),i("code",null,"full(Full Fine-Tuning, 全量微调)"),a("指对模型的"),i("code",null,"所有参数"),a("进行微调"),i("br"),a(),i("code",null,"freeze(Freeze Fine-Tuning, 冻结微调)"),a("指"),i("code",null,"冻结"),a("模型的某些层或全部层，仅微调 "),i("code",null,"特定的参数")])],-1)),s[5]||(s[5]=i("tr",null,[i("td",null,"检查点路径"),i("td",null,[a("保存训练的"),i("code",null,"中间结果")]),i("td",null,[a("此地址保存训练后的模型权重，Train 模式不需要填，会默认存入 /save文件中；其他模式填训练好的模型路径。如果训练中断，可以从检查点"),i("code",null,"继续训练")])],-1)),s[6]||(s[6]=i("tr",null,[i("td",null,"RoPE插值方法、加速方式"),i("td",null,"加速模型训练"),i("td",null,"一般不建议使用，会损失模型精度")],-1)),s[7]||(s[7]=i("tr",null,[i("td",null,[i("a",{href:"#train-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"},"Train")]),i("td",null,"对模型进行训练"),i("td")],-1)),s[8]||(s[8]=i("tr",null,[i("td",null,[i("a",{href:"#"},"Evaluate & Predict")]),i("td",null,"对模型进行评估、验证"),i("td")],-1)),s[9]||(s[9]=i("tr",null,[i("td",null,[i("a",{href:"#3"},"Chat")]),i("td",null,"使用模型推理"),i("td")],-1)),i("tr",null,[i("td",null,[d(t,{href:""},{default:r(()=>s[0]||(s[0]=[a("Export",-1)])),_:1,__:[0]})]),s[1]||(s[1]=i("td",null,"对模型进行合并和导出",-1)),s[2]||(s[2]=i("td",null,null,-1))])])]),s[14]||(s[14]=l(`<h2 id="训练数据的准备" tabindex="-1"><a class="header-anchor" href="#训练数据的准备"><span>训练数据的准备</span></a></h2><h3 id="数据处理介绍" tabindex="-1"><a class="header-anchor" href="#数据处理介绍"><span>数据处理介绍</span></a></h3><p>LLaMA Factory 的数据集配置分为两步：</p><ol><li>准备数据：将训练数据存放至 <code>.json</code> 文件中，然后将训练数据上传至 <code>LLaMA-Factory</code> 的 <code>./data</code> 目录下</li><li>注册数据：配置 <code>./data</code> 中 的 <code>data_info.json</code> 文件，把训练数据路径（文件名）补充进入即可。名称可以自由命名</li></ol><div class="hint-container note"><p class="hint-container-title">注</p><p><code>LLaMA-Factory</code> 目前只支持 <code>Alpaca</code> 和 <code>ShareGPT</code> 两种数据格式，分别适用于 <code>指令监督微调</code> 和 <code>多轮对话任务</code> 。<br> 具体请查看 <a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/data_preparation.html" target="_blank" rel="noopener noreferrer">数据处理-LLaMA Factory</a></p></div><h3 id="训练数据准备" tabindex="-1"><a class="header-anchor" href="#训练数据准备"><span>训练数据准备</span></a></h3><p>使用LLaMA Factory内置的自我认知数据（/data 文件中的 <code>identity.json</code> 文件），其原始格式是这样的：</p><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-json"><span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  {</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">instruction</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">hi</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">output</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  },</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">  ......</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  {</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">instruction</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">你好</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">output</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">您好，我是 {{name}}，一个由 {{author}} 打造的人工智能助手，请问有什么可以帮助您的吗？</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  },</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  {</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">instruction</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">你是谁</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">output</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">您好，我是由 {{author}} 发明的 {{name}}。我可以为您提供多种多样的服务，比如翻译、写代码、闲聊、为您答疑解惑等。</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  },</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">  ......</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>属于Alpaca 形式的 指令监督微调数据集，核心有4个键，分别对应着微调的四个指令：</p><ol><li><code>instruction</code>（必填）：明确的任务指令，模型需要根据该指令生成输出。</li><li><code>input</code>（可选）：与任务相关的背景信息或上下文。在 RAG任务中，input input参数可以用于提供检索到的外部知识或上下文信息，帮助模型生成更准确的回答</li><li><code>output</code>（必填）：模型需要生成的正确回答。</li><li><code>system</code>（可选）：系统提示词，用于定义任务的上下文。</li><li><code>history</code>（可选）：历史对话记录，用于多轮对话任务。用于控制多轮对话，指上下文信息，若无历史对话，则为[]。<br> 注：如果有多轮对话，那么history 这个list是有先后顺序的。list[0]为第一轮，list[1]为第二轮，依次向后排序，而instruction 是存放最新一轮对话信息</li></ol><h3 id="认知修改" tabindex="-1"><a class="header-anchor" href="#认知修改"><span>认知修改</span></a></h3>`,11)),i("p",null,[s[11]||(s[11]=a("将 ",-1)),s[12]||(s[12]=i("code",null,"identity.json",-1)),a(" 文件中的"+n(e.name)+"和"+n(e.auther)+"替换成为需要的名称信息",1)]),s[15]||(s[15]=l(`<div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">sed</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">s/{{name}}/yourModelName/g</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> identity.json</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">sed</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">s/{{author}}/YourName/g</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> identity.json</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>因为该文件是默认内置文件，因此不需要对数据进行注册</p><h2 id="train-模型训练" tabindex="-1"><a class="header-anchor" href="#train-模型训练"><span>Train 模型训练</span></a></h2><p>训练阶段（训练方式）</p><ul><li>Supervised Fine-Tuning （监督微调）监督微调是最常见的微调方法，使用标注好的数据对预训练模型进行进一步训练，以适应特定任务（如分类、问答等）。</li><li>Reward Modeling（奖励建模）奖励建模是一种用于优化模型输出质量的方法，通常用于强化学习（RL）的上下文中。</li><li>PPO（Proximal Policy Optimization） PPO 是一种基于强化学习的微调方法，用于优化模型的输出策略。</li><li>DPO （Direct Preference Optimization）DPO 是一种基于人类偏好的直接优化方法，用于训练模型以生成更符合人类偏好的输出。 - Pre-Training（预训练）预训练是指从头开始训练一个大模型，通常使用大量的无监督数据（如文本语料库）。预训练的目标是让模型学习通用的语言知识和模式。</li></ul><p>数据路径：默认data，指的是 LLaMA-Factory 目录下的/data 相对路径。此文件夹中用于存放训练所需要的数据</p><p>数据集：支持选择多个数据集，支持预览</p><hr><p>学习率：可以不用修改</p><p>训练轮次：根据数据集大小调整，可以调的高一些，比如1000，因为可以随时停止</p><p>梯度：根据显存情况调整 最大样本数：根据数据集大小和训练需求设置。主要是防止数据量过大导致的内存溢出问题 计算类型：这里支持混合精度训练选择（fp16或 bf16）bf16的效果更佳一些。 bf16对某些架构是不支持的，和硬件有关（GPU的架构）。如果你的硬件不支持 BF16，可以选择 FP16 进行混合精度训练。 NVIDIA 4090 支持 BF16运算。我的服务器是 NVIDIA A10 GPU，是基于 Ampere 架构 的 GPU。同样也支持bf16运算。可以先选择bf16，如果不支持会报错，然后再选择fp16就行</p><blockquote><p>混合精度训练是一种结合了半精度浮点数（FP16 或 BF16）和单精度浮点数（FP32）的训练技术。其核心在于：</p><ul><li>使用 FP16 或 BF16 进行大部分计算，以减少内存占用和加速计算。</li><li>保留关键部分（如优化器参数）以 FP32 存储，以避免数值精度问题。</li><li>适用于 GPU 和支持 BF16 的硬件（如 NVIDIA Ampere 架构）</li></ul></blockquote><p>截断长度：根据任务需求/数据集配置，通常默认值为 1024 批处理大小 验证集比例</p><p>其他参数：</p><p>日志间隔：多久输出日志信息 保存问题：多久保存权重</p><p>LoRA参数设置 LoRA秩：LoRA秩越大模型越大，默认秩是8 参数配置好后，点击开始，即可进行训练。</p><p>通过命令行开始训练 预览命令</p><p>输出目录：模型训练结果的保存位置，默认是/saves文件</p><p>训练时会实时显示损失变化。</p><p>设备数量（和服务器的实际情况有关），若有多张卡，就可以使用DeepSpeed进行训练的加速。若只有1张卡那么就不要使用DeepSpeed，否则会造成显存占比过高，效果反而会变差。</p><p>Num example指训练数据有多少条样本 Num epoch 指我们配置的epoch ，要训练多少轮次 total training batch size=80 计算出的整体训练批次 （基于输入长度计算得到） Total optimization steps ：计算出来的要跑的epoch { loss:xxx , learning_rate : xxx ,epoch:0.5 } 此处的epoch指是 epoch 表示当前训练进度相对于整个数据集的比例.。 作用：帮助开发者了解训练进度。例如，如果总 epoch 是 10，epoch: 0.5 表示模型已经完成了 5% 的总训练进度。</p><p>输出文件结构 模型训练好后，会保存至 LLaMA-Factory 的 /saves文件中</p><p>路径：/saves/基座模型名称/微调方法</p><p>由于保存间隔设置的100，因此每100个步长保存一次模型的权重</p><p>我们看下checkpoint-800文件，下图红框圈出来部分为lora 模型，其中</p><p>traning_args.yaml 文件为模型训练的参数信息</p><p>save_steps 为模型训练的步长 output_dir 为模型保存路径</p><p>adapter_config.json为lora的参数信息</p><p>beft_type(微调方法)：LORA base_model_name_or_path： 基座模型 task_type：任务类型，生成式模型 CAUSAL_LM adapter_model.safetensors：模型权重文件 trainer_state.json：模型训练状态文件</p><p>epoch：训练轮次 eval_steps：基于验证集的比例得到的，每隔多少个步长会做一次验证 global_step：本次步长是多少 log_history：历史轮次的学习率、loss、步长等信息</p><p>整体训练完后，会保存training的LOSS和eval的LOSS 图</p>`,31))])}const y=h(u,[["render",c]]),m=JSON.parse('{"path":"/notes/aillm/fine-tuning/lora/","title":"改变大模型自我认知","lang":"zh-CN","frontmatter":{"title":"改变大模型自我认知","createTime":"2025/03/27 16:27:43","permalink":"/notes/aillm/fine-tuning/lora/","description":"目的 使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变 启动LLaMA Factory 进入 LLaMA-Factory 目录下 使用此命令开启llamafactory，若界面关闭模型训练便会终止 若希望后台一直训练，则使用nohup 调起即可 关闭则 使用kill 指定进程名即可 若希望在使用llamafactory ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"改变大模型自我认知\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-12-11T16:51:13.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://nov1ce-lee.github.io/notes/aillm/fine-tuning/lora/"}],["meta",{"property":"og:site_name","content":"novice.log"}],["meta",{"property":"og:title","content":"改变大模型自我认知"}],["meta",{"property":"og:description","content":"目的 使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变 启动LLaMA Factory 进入 LLaMA-Factory 目录下 使用此命令开启llamafactory，若界面关闭模型训练便会终止 若希望后台一直训练，则使用nohup 调起即可 关闭则 使用kill 指定进程名即可 若希望在使用llamafactory ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-11T16:51:13.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-11T16:51:13.000Z"}]]},"readingTime":{"minutes":7.34,"words":2202},"git":{"createdTime":1765471873000,"updatedTime":1765471873000,"contributors":[{"name":"nov1ce","username":"nov1ce","email":"289836737@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/nov1ce?v=4","url":"https://github.com/nov1ce"}]},"autoDesc":true,"filePathRelative":"notes/aillm/微调训练/LLaMA Factory/5.LoRA微调.md","headers":[]}');export{y as comp,m as data};

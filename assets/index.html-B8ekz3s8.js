import{_ as i,c as a,e,o as l}from"./app-BunmiVsH.js";const h={};function n(t,s){return l(),a("div",null,s[0]||(s[0]=[e(`<div class="hint-container note"><p class="hint-container-title">注</p><p>请确保在 <code>LLaMA-Factory</code> 目录下执行下述命令。</p></div><h2 id="目录" tabindex="-1"><a class="header-anchor" href="#目录"><span>目录</span></a></h2><ul><li><a href="#lora-%E5%BE%AE%E8%B0%83">LoRA 微调</a></li><li><a href="#qlora-%E5%BE%AE%E8%B0%83">QLoRA 微调</a></li><li><a href="#%E5%85%A8%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83">全参数微调</a></li><li><a href="#%E5%90%88%E5%B9%B6-lora-%E9%80%82%E9%85%8D%E5%99%A8%E4%B8%8E%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96">合并 LoRA 适配器与模型量化</a></li><li><a href="#%E6%8E%A8%E7%90%86-lora-%E6%A8%A1%E5%9E%8B">推理 LoRA 模型</a></li><li><a href="#%E6%9D%82%E9%A1%B9">杂项</a></li></ul><p>使用 <code>CUDA_VISIBLE_DEVICES</code>（GPU）或 <code>ASCEND_RT_VISIBLE_DEVICES</code>（NPU）选择计算设备。</p><p>LLaMA-Factory 默认使用所有可见的计算设备。</p><h2 id="示例" tabindex="-1"><a class="header-anchor" href="#示例"><span>示例</span></a></h2><h3 id="lora-微调" tabindex="-1"><a class="header-anchor" href="#lora-微调"><span>LoRA 微调</span></a></h3><h4 id="增量-预训练" tabindex="-1"><a class="header-anchor" href="#增量-预训练"><span>（增量）预训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_pretrain.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="指令监督微调" tabindex="-1"><a class="header-anchor" href="#指令监督微调"><span>指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="多模态指令监督微调" tabindex="-1"><a class="header-anchor" href="#多模态指令监督微调"><span>多模态指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llava1_5_lora_sft.yaml</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/qwen2vl_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="dpo-orpo-simpo-训练" tabindex="-1"><a class="header-anchor" href="#dpo-orpo-simpo-训练"><span>DPO/ORPO/SimPO 训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_dpo.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="多模态-dpo-orpo-simpo-训练" tabindex="-1"><a class="header-anchor" href="#多模态-dpo-orpo-simpo-训练"><span>多模态 DPO/ORPO/SimPO 训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/qwen2vl_lora_dpo.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="奖励模型训练" tabindex="-1"><a class="header-anchor" href="#奖励模型训练"><span>奖励模型训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_reward.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="ppo-训练" tabindex="-1"><a class="header-anchor" href="#ppo-训练"><span>PPO 训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_ppo.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="kto-训练" tabindex="-1"><a class="header-anchor" href="#kto-训练"><span>KTO 训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_kto.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="预处理数据集" tabindex="-1"><a class="header-anchor" href="#预处理数据集"><span>预处理数据集</span></a></h4><p>对于大数据集有帮助，在配置中使用 <code>tokenized_path</code> 以加载预处理后的数据集。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_preprocess.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="在-mmlu-cmmlu-c-eval-上评估" tabindex="-1"><a class="header-anchor" href="#在-mmlu-cmmlu-c-eval-上评估"><span>在 MMLU/CMMLU/C-Eval 上评估</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> eval</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_eval.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="多机指令监督微调" tabindex="-1"><a class="header-anchor" href="#多机指令监督微调"><span>多机指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NNODES</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">2</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NODE_RANK</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">0</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_ADDR</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">192.168.0.1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_PORT</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">29500</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_sft.yaml</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NNODES</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">2</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NODE_RANK</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_ADDR</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">192.168.0.1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_PORT</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">29500</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="使用-deepspeed-zero-3-平均分配显存" tabindex="-1"><a class="header-anchor" href="#使用-deepspeed-zero-3-平均分配显存"><span>使用 DeepSpeed ZeRO-3 平均分配显存</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_sft_ds3.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用-ray-在-4-张-gpu-上微调" tabindex="-1"><a class="header-anchor" href="#使用-ray-在-4-张-gpu-上微调"><span>使用 Ray 在 4 张 GPU 上微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">USE_RAY</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_lora/llama3_lora_sft_ray.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="qlora-微调" tabindex="-1"><a class="header-anchor" href="#qlora-微调"><span>QLoRA 微调</span></a></h3><h4 id="基于-4-8-比特-bitsandbytes-hqq-eetq-量化进行指令监督微调-推荐" tabindex="-1"><a class="header-anchor" href="#基于-4-8-比特-bitsandbytes-hqq-eetq-量化进行指令监督微调-推荐"><span>基于 4/8 比特 Bitsandbytes/HQQ/EETQ 量化进行指令监督微调（推荐）</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_qlora/llama3_lora_sft_otfq.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="在-npu-上基于-4-比特-bitsandbytes-量化进行指令监督微调" tabindex="-1"><a class="header-anchor" href="#在-npu-上基于-4-比特-bitsandbytes-量化进行指令监督微调"><span>在 NPU 上基于 4 比特 Bitsandbytes 量化进行指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_qlora/llama3_lora_sft_bnb_npu.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="基于-4-8-比特-gptq-量化进行指令监督微调" tabindex="-1"><a class="header-anchor" href="#基于-4-8-比特-gptq-量化进行指令监督微调"><span>基于 4/8 比特 GPTQ 量化进行指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_qlora/llama3_lora_sft_gptq.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="基于-4-比特-awq-量化进行指令监督微调" tabindex="-1"><a class="header-anchor" href="#基于-4-比特-awq-量化进行指令监督微调"><span>基于 4 比特 AWQ 量化进行指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_qlora/llama3_lora_sft_awq.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="基于-2-比特-aqlm-量化进行指令监督微调" tabindex="-1"><a class="header-anchor" href="#基于-2-比特-aqlm-量化进行指令监督微调"><span>基于 2 比特 AQLM 量化进行指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_qlora/llama3_lora_sft_aqlm.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="全参数微调" tabindex="-1"><a class="header-anchor" href="#全参数微调"><span>全参数微调</span></a></h3><h4 id="在单机上进行指令监督微调" tabindex="-1"><a class="header-anchor" href="#在单机上进行指令监督微调"><span>在单机上进行指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_full/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="在多机上进行指令监督微调" tabindex="-1"><a class="header-anchor" href="#在多机上进行指令监督微调"><span>在多机上进行指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NNODES</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">2</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NODE_RANK</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">0</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_ADDR</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">192.168.0.1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_PORT</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">29500</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_full/llama3_full_sft.yaml</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NNODES</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">2</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> NODE_RANK</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_ADDR</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">192.168.0.1</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> MASTER_PORT</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">29500</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_full/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="多模态指令监督微调-1" tabindex="-1"><a class="header-anchor" href="#多模态指令监督微调-1"><span>多模态指令监督微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">FORCE_TORCHRUN</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">1</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/train_full/qwen2vl_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="合并-lora-适配器与模型量化" tabindex="-1"><a class="header-anchor" href="#合并-lora-适配器与模型量化"><span>合并 LoRA 适配器与模型量化</span></a></h3><h4 id="合并-lora-适配器" tabindex="-1"><a class="header-anchor" href="#合并-lora-适配器"><span>合并 LoRA 适配器</span></a></h4><p>注：请勿使用量化后的模型或 <code>quantization_bit</code> 参数来合并 LoRA 适配器。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> export</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/merge_lora/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用-autogptq-量化模型" tabindex="-1"><a class="header-anchor" href="#使用-autogptq-量化模型"><span>使用 AutoGPTQ 量化模型</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> export</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/merge_lora/llama3_gptq.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="保存-ollama-配置文件" tabindex="-1"><a class="header-anchor" href="#保存-ollama-配置文件"><span>保存 Ollama 配置文件</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> export</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/merge_lora/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="推理-lora-模型" tabindex="-1"><a class="header-anchor" href="#推理-lora-模型"><span>推理 LoRA 模型</span></a></h3><h4 id="使用-vllm-tp-批量推理" tabindex="-1"><a class="header-anchor" href="#使用-vllm-tp-批量推理"><span>使用 vLLM+TP 批量推理</span></a></h4><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-"><span class="line"><span>python scripts/vllm_infer.py --model_name_or_path path_to_merged_model --dataset alpaca_en_demo</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用命令行对话框" tabindex="-1"><a class="header-anchor" href="#使用命令行对话框"><span>使用命令行对话框</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> chat</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/inference/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用浏览器对话框" tabindex="-1"><a class="header-anchor" href="#使用浏览器对话框"><span>使用浏览器对话框</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webchat</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/inference/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="启动-openai-风格-api" tabindex="-1"><a class="header-anchor" href="#启动-openai-风格-api"><span>启动 OpenAI 风格 API</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> api</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/inference/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="杂项" tabindex="-1"><a class="header-anchor" href="#杂项"><span>杂项</span></a></h3><h4 id="使用-galore-进行全参数训练" tabindex="-1"><a class="header-anchor" href="#使用-galore-进行全参数训练"><span>使用 GaLore 进行全参数训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/galore/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用-apollo-进行全参数训练" tabindex="-1"><a class="header-anchor" href="#使用-apollo-进行全参数训练"><span>使用 APOLLO 进行全参数训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/apollo/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用-badam-进行全参数训练" tabindex="-1"><a class="header-anchor" href="#使用-badam-进行全参数训练"><span>使用 BAdam 进行全参数训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/badam/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="使用-adam-mini-进行全参数训练" tabindex="-1"><a class="header-anchor" href="#使用-adam-mini-进行全参数训练"><span>使用 Adam-mini 进行全参数训练</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/adam_mini/qwen2_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="lora-微调-1" tabindex="-1"><a class="header-anchor" href="#lora-微调-1"><span>LoRA+ 微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/loraplus/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="pissa-微调" tabindex="-1"><a class="header-anchor" href="#pissa-微调"><span>PiSSA 微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/pissa/llama3_lora_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="深度混合微调" tabindex="-1"><a class="header-anchor" href="#深度混合微调"><span>深度混合微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/mod/llama3_full_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="llama-pro-微调" tabindex="-1"><a class="header-anchor" href="#llama-pro-微调"><span>LLaMA-Pro 微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">bash</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/llama_pro/expand.sh</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/llama_pro/llama3_freeze_sft.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="fsdp-qlora-微调" tabindex="-1"><a class="header-anchor" href="#fsdp-qlora-微调"><span>FSDP+QLoRA 微调</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">bash</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/fsdp_qlora/train.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h4 id="计算-bleu-和-rouge-分数" tabindex="-1"><a class="header-anchor" href="#计算-bleu-和-rouge-分数"><span>计算 BLEU 和 ROUGE 分数</span></a></h4><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> train</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> examples/extras/nlg_eval/llama3_lora_predict.yaml</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div>`,90)]))}const d=i(h,[["render",n]]),k=JSON.parse('{"path":"/notes/aillm/fine-tuning/llama-factory/advance/","title":"高级用法","lang":"zh-CN","frontmatter":{"title":"高级用法","createTime":"2025/03/16 14:05:04","permalink":"/notes/aillm/fine-tuning/llama-factory/advance/","description":"注 请确保在 LLaMA-Factory 目录下执行下述命令。 目录 LoRA 微调 QLoRA 微调 全参数微调 合并 LoRA 适配器与模型量化 推理 LoRA 模型 杂项 使用 CUDA_VISIBLE_DEVICES（GPU）或 ASCEND_RT_VISIBLE_DEVICES（NPU）选择计算设备。 LLaMA-Factory 默认使用所有...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"高级用法\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-12-11T16:51:13.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://nov1ce-lee.github.io/notes/aillm/fine-tuning/llama-factory/advance/"}],["meta",{"property":"og:site_name","content":"novice.log"}],["meta",{"property":"og:title","content":"高级用法"}],["meta",{"property":"og:description","content":"注 请确保在 LLaMA-Factory 目录下执行下述命令。 目录 LoRA 微调 QLoRA 微调 全参数微调 合并 LoRA 适配器与模型量化 推理 LoRA 模型 杂项 使用 CUDA_VISIBLE_DEVICES（GPU）或 ASCEND_RT_VISIBLE_DEVICES（NPU）选择计算设备。 LLaMA-Factory 默认使用所有..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-11T16:51:13.000Z"}],["meta",{"property":"article:modified_time","content":"2025-12-11T16:51:13.000Z"}]]},"readingTime":{"minutes":2.56,"words":767},"git":{"createdTime":1765471873000,"updatedTime":1765471873000,"contributors":[{"name":"nov1ce","username":"nov1ce","email":"289836737@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/nov1ce?v=4","url":"https://github.com/nov1ce"}]},"autoDesc":true,"filePathRelative":"notes/aillm/微调训练/LLaMA Factory/2.高级用法.md","headers":[]}');export{d as comp,k as data};

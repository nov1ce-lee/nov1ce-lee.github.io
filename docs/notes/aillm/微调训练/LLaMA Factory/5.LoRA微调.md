---
title: 改变大模型自我认知
createTime: 2025/03/27 16:27:43
permalink: /notes/aillm/fine-tuning/lora/
---
## 目的
使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变

## 启动LLaMA Factory

- 进入 LLaMA-Factory 目录下
```bash
cd LLaMA-Factory
```

- 使用此命令开启llamafactory，若界面关闭模型训练便会终止
```bash
llamafactory-cli webui
```

- 若希望后台一直训练，则使用nohup 调起即可
```bash
nohup llamafactory-cli webui & 
```
- 关闭则 使用kill  指定进程名即可
```bash
kill -9 
```

- 若希望在使用llamafactory 使用指定显卡，那么使用这行命令：
```bash
CUDA_VISIBLE_DEVICES=6 llamafactory-cli webui
```

## 模块介绍

|modules|function|note|
|---|---|---|
|模型路径|支持 `huggingface` 在线路径，或者本地的模型路径|注意是绝对路径，`.config` 文件上一层|
|微调方法|支持 `lora / freeze / full` 方法|`lora(Low-Rank Adaptation)`指通过在模型的某些层中添加`低秩矩阵`来实现微调<br>  `full(Full Fine-Tuning, 全量微调)`指对模型的`所有参数`进行微调<br> `freeze(Freeze Fine-Tuning, 冻结微调)`指`冻结`模型的某些层或全部层，仅微调 `特定的参数`|
|检查点路径|保存训练的`中间结果`|此地址保存训练后的模型权重，Train 模式不需要填，会默认存入 /save文件中；其他模式填训练好的模型路径。如果训练中断，可以从检查点`继续训练`|
|RoPE插值方法、加速方式|加速模型训练|一般不建议使用，会损失模型精度|
|[Train](#train-模型训练)|对模型进行训练||
|[Evaluate & Predict](#)|对模型进行评估、验证||
|[Chat](#3)|使用模型推理||
|[Export]()|对模型进行合并和导出||

## 训练数据的准备
### 数据处理介绍
LLaMA Factory 的数据集配置分为两步：
1. 准备数据：将训练数据存放至 `.json` 文件中，然后将训练数据上传至 `LLaMA-Factory` 的 `./data` 目录下
2. 注册数据：配置 `./data` 中 的 `data_info.json` 文件，把训练数据路径（文件名）补充进入即可。名称可以自由命名      

:::note
`LLaMA-Factory` 目前只支持 `Alpaca` 和 `ShareGPT` 两种数据格式，分别适用于 `指令监督微调` 和 `多轮对话任务` 。  
具体请查看 [数据处理-LLaMA Factory](https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/data_preparation.html)
:::

### 训练数据准备
使用LLaMA Factory内置的自我认知数据（/data 文件中的 `identity.json` 文件），其原始格式是这样的：
```json
[
  {
    "instruction": "hi",
    "input": "",
    "output": "Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?"
  },
  ......
  {
    "instruction": "你好",
    "input": "",
    "output": "您好，我是 {{name}}，一个由 {{author}} 打造的人工智能助手，请问有什么可以帮助您的吗？"
  },
  {
    "instruction": "你是谁",
    "input": "",
    "output": "您好，我是由 {{author}} 发明的 {{name}}。我可以为您提供多种多样的服务，比如翻译、写代码、闲聊、为您答疑解惑等。"
  },
  ......
]
```

属于Alpaca 形式的 指令监督微调数据集，核心有4个键，分别对应着微调的四个指令：
1. `instruction`（必填）：明确的任务指令，模型需要根据该指令生成输出。
2. `input`（可选）：与任务相关的背景信息或上下文。在 RAG任务中，input input参数可以用于提供检索到的外部知识或上下文信息，帮助模型生成更准确的回答
3. `output`（必填）：模型需要生成的正确回答。
4. `system`（可选）：系统提示词，用于定义任务的上下文。 
5. `history`（可选）：历史对话记录，用于多轮对话任务。用于控制多轮对话，指上下文信息，若无历史对话，则为[]。  
注：如果有多轮对话，那么history 这个list是有先后顺序的。list[0]为第一轮，list[1]为第二轮，依次向后排序，而instruction 是存放最新一轮对话信息


### 认知修改
将 `identity.json` 文件中的{{name}}和{{auther}}替换成为需要的名称信息
```bash
sed -i 's/{{name}}/yourModelName/g' identity.json
sed -i 's/{{author}}/YourName/g' identity.json
```
因为该文件是默认内置文件，因此不需要对数据进行注册

## Train 模型训练
训练阶段（训练方式）
- Supervised Fine-Tuning （监督微调）监督微调是最常见的微调方法，使用标注好的数据对预训练模型进行进一步训练，以适应特定任务（如分类、问答等）。
- Reward Modeling（奖励建模）奖励建模是一种用于优化模型输出质量的方法，通常用于强化学习（RL）的上下文中。
- PPO（Proximal Policy Optimization） PPO 是一种基于强化学习的微调方法，用于优化模型的输出策略。
- DPO （Direct Preference Optimization）DPO 是一种基于人类偏好的直接优化方法，用于训练模型以生成更符合人类偏好的输出。 - Pre-Training（预训练）预训练是指从头开始训练一个大模型，通常使用大量的无监督数据（如文本语料库）。预训练的目标是让模型学习通用的语言知识和模式。

数据路径：默认data，指的是 LLaMA-Factory 目录下的/data 相对路径。此文件夹中用于存放训练所需要的数据

数据集：支持选择多个数据集，支持预览

______

学习率：可以不用修改

训练轮次：根据数据集大小调整，可以调的高一些，比如1000，因为可以随时停止

梯度：根据显存情况调整
最大样本数：根据数据集大小和训练需求设置。主要是防止数据量过大导致的内存溢出问题
计算类型：这里支持混合精度训练选择（fp16或 bf16）bf16的效果更佳一些。 bf16对某些架构是不支持的，和硬件有关（GPU的架构）。如果你的硬件不支持 BF16，可以选择 FP16 进行混合精度训练。 NVIDIA 4090 支持 BF16运算。我的服务器是 NVIDIA A10 GPU，是基于 Ampere 架构 的 GPU。同样也支持bf16运算。可以先选择bf16，如果不支持会报错，然后再选择fp16就行
>混合精度训练是一种结合了半精度浮点数（FP16 或 BF16）和单精度浮点数（FP32）的训练技术。其核心在于：
>- 使用 FP16 或 BF16 进行大部分计算，以减少内存占用和加速计算。
>- 保留关键部分（如优化器参数）以 FP32 存储，以避免数值精度问题。
>- 适用于 GPU 和支持 BF16 的硬件（如 NVIDIA Ampere 架构）

截断长度：根据任务需求/数据集配置，通常默认值为 1024
批处理大小
验证集比例

其他参数：

日志间隔：多久输出日志信息
保存问题：多久保存权重

LoRA参数设置
LoRA秩：LoRA秩越大模型越大，默认秩是8
参数配置好后，点击开始，即可进行训练。

通过命令行开始训练
预览命令


输出目录：模型训练结果的保存位置，默认是/saves文件

训练时会实时显示损失变化。

设备数量（和服务器的实际情况有关），若有多张卡，就可以使用DeepSpeed进行训练的加速。若只有1张卡那么就不要使用DeepSpeed，否则会造成显存占比过高，效果反而会变差。


Num example指训练数据有多少条样本
Num epoch 指我们配置的epoch ，要训练多少轮次
total training batch size=80 计算出的整体训练批次 （基于输入长度计算得到）
Total optimization steps ：计算出来的要跑的epoch
{ loss:xxx , learning_rate : xxx ,epoch:0.5 } 此处的epoch指是 epoch 表示当前训练进度相对于整个数据集的比例.。
作用：帮助开发者了解训练进度。例如，如果总 epoch 是 10，epoch: 0.5 表示模型已经完成了 5% 的总训练进度。

输出文件结构
模型训练好后，会保存至 LLaMA-Factory 的 /saves文件中

路径：/saves/基座模型名称/微调方法


由于保存间隔设置的100，因此每100个步长保存一次模型的权重

我们看下checkpoint-800文件，下图红框圈出来部分为lora 模型，其中

traning_args.yaml 文件为模型训练的参数信息

save_steps 为模型训练的步长
output_dir 为模型保存路径

adapter_config.json为lora的参数信息

beft_type(微调方法)：LORA
base_model_name_or_path： 基座模型
task_type：任务类型，生成式模型 CAUSAL_LM
adapter_model.safetensors：模型权重文件
trainer_state.json：模型训练状态文件

epoch：训练轮次
eval_steps：基于验证集的比例得到的，每隔多少个步长会做一次验证
global_step：本次步长是多少
log_history：历史轮次的学习率、loss、步长等信息

整体训练完后，会保存training的LOSS和eval的LOSS 图




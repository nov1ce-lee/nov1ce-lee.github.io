---
title: 模型微调常用步骤
createTime: 2025/03/31 17:03:40
permalink: /notes/aillm/fine-tuning/process/
---

### 启动 LLama-Factory 的可视化微调界面
```bash
llamafactory-cli webui
```

### 从 HuggingFace 上下载基座模型
- 创建文件夹统一存放所有基座模型
```bash
mkdir hugging-Face
```
- 修改 HuggingFace 的镜像源
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

- 修改模型下载的默认位置
```bash
export HF_HOME=/home/jingzhao/fine-tuning/hugging-face
```
:::note
注意：这种配置方式只在当前 `shell` 会话中有效，如果你希望这个环境变量在每次启动终端时都生效，可以将其添加到你的用户配置文件中（修改 ~/.bashrc 或 ~/.zshrc）
:::
- 检查环境变量是否生效
```bash
echo $HF_ENDPOINT
echo $HF_HOME
```

- 安装 HuggingFace 官方下载工具
```bash
pip install -U huggingface_hub
```
- 执行下载命令（可以在[HF镜像站](https://hf-mirror.com/)和[Hugging Face官网](https://huggingface.co/models)找到模型名称）
```bash
huggingface-cli download --resume-download model-name
```

### 在可视化页面加载模型
- 模型路径为模型特定快照的唯一哈希值，打开下载路径即可看到，复制文件路径即可

### 准备数据集
- 修改 dataset_info.json 文件，添加如下配置：
```json
"your_dataset": {
    "file_name": "your_dataset.json"
},
```
- 将数据集 `your_dataset.json` 放到 `LLama-Factory` 的 `data` 目录下

### 启动训练
- 页面上点击`启动训练`，或复制命令到终端启动训练  
实践中推荐用 `nohup` 命令将训练任务放到后台执行，这样即使关闭终端任务也会继续运行。同时将日志重定向到文件中保存下来
- 在训练过程中注意观察`损失曲线`，尽可能将损失降到最低    
如损失降低太慢，尝试增大`学习率`  
如训练结束损失还呈下降趋势，增大`训练轮数`确保拟合

### 微调结束，评估微调效果
- 观察损失曲线的变化；观察最终损失        
- 在交互页面上通过预测/对话等方式测试微调好的效果     
- 检查点：保存的是模型在训练过程中的一个中间状态，包含了模型权重、训练过程中使用的配置（如学习率、批次大小）等信息，对LoRA来说，检查点包含了训练得到的 B 和 A 这两个低秩矩阵的权重

若微调效果不理想，你可以：  
- 使用更强的预训练模型
- 增加数据量
- 优化数据质量（数据清洗、数据增强等，可学习相关论文如何实现）
- 调整训练参数，如学习率、训练轮数、优化器、批次大小等等

### 导出合并后的模型
>为什么要合并：因为 LoRA 只是通过低秩矩阵调整原始模型的部分权重，而不直接修改原模型的权重。合并步骤将 LoRA 权重与原始模型权重融合生成一个完整的模型

先创建目录，用于存放导出后的模型
```bash
mkdir -p models/merged
```
在页面上配置导出路径，导出即可

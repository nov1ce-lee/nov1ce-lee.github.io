---
title: 使用手册
createTime: 2025/03/16 13:24:26
permalink: /notes/aillm/fine-tuning/llama-factory/
---
## 官方介绍
![](https://obsidian-pic-1326566629.cos.ap-shanghai.myqcloud.com/20250728144422853.png)
[官方文档](https://llamafactory.readthedocs.io/zh-cn/latest/index.html)     
[GitHub](https://github.com/hiyouga/LLaMA-Factory)
## 如何使用
### 安装
:::important
此步骤为必需，建议使用虚拟环境安装避免不同项目包冲突
:::
```bash
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]"
```
### 数据准备
数据集文件的格式：[规范文档](https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README_zh.md)  
你可以使用 HuggingFace / ModelScope / Modelers 上的数据集或加载本地数据集
:::note
当你使用自定义数据集时，请更新`data/dataset_info.json`文件
:::
### 快速开始
下面三行命令分别对`Llama3-8B-Instruct`模型进行`LoRA`微调、推理和合并
```bash
llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml
llamafactory-cli chat examples/inference/llama3_lora_sft.yaml
llamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml
```
### 可视化微调
`LLaMA Board`可视化微调(由[Gradio](https://github.com/gradio-app/gradio)驱动):
```bash
llamafactory-cli webui
```
### 高级用法（包括多 GPU 微调）

请参考[高级用法](高级用法.md)(本页面)     
& [大模型微调示例脚本](https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README_zh.md)

## 模型下载
### 从魔搭社区下载
```bash
export USE_MODELSCOPE_HUB=1 # Windows 使用 `set USE_MODELSCOPE_HUB=1`
```
将 `model_name_or_path` 设置为模型 ID 来加载对应的模型。在[魔搭社区](https://modelscope.cn/models)查看所有可用的模型，例如 `LLM-Research/Meta-Llama-3-8B-Instruct`
### 从魔乐社区下载
```bash
export USE_OPENMIND_HUB=1 # Windows 使用 `set USE_OPENMIND_HUB=1`
```
将 `model_name_or_path` 设置为模型 ID 来加载对应的模型。在[魔乐社区](https://modelers.cn/models)查看所有可用的模型，例如 `TeleAI/TeleChat-7B-pt`

## 硬件依赖估算值

| 方法 | 精度 | 7B | 14B | 30B | 70B | xB | 
|-------|-------|-------|-------|-------|-------|-------|
| Full (bf16 or fp16) | 32 | 120GB | 240GB | 600GB | 1200GB | 18xGB |   
| Full (pure_bf16) | 16 | 60GB | 120GB | 300GB | 600GB | 8xGB | 
| Freeze/LoRA/GaLore/APOLLO/BAdam | 16 | 16GB | 32GB | 64GB | 160GB | 2xGB |    
| QLoRA | 8 | 10GB | 20GB | 40GB | 80GB | xGB | 
| QLoRA | 4 | 6GB | 12GB | 24GB | 48GB | x/2GB |    
| QLoRA | 2 | 4GB | 8GB | 16GB | 24GB | x/4GB |
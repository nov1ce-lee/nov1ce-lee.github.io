<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.24" /><meta name="theme" content="VuePress Theme Plume 1.0.0-rc.159" /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"改变大模型自我认知","image":[""],"dateModified":"2025-12-11T16:51:13.000Z","author":[]}</script><meta property="og:url" content="https://nov1ce-lee.github.io/notes/aillm/fine-tuning/lora/"><meta property="og:site_name" content="novice.log"><meta property="og:title" content="改变大模型自我认知"><meta property="og:description" content="目的 使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变 启动LLaMA Factory 进入 LLaMA-Factory 目录下 使用此命令开启llamafactory，若界面关闭模型训练便会终止 若希望后台一直训练，则使用nohup 调起即可 关闭则 使用kill 指定进程名即可 若希望在使用llamafactory ..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-12-11T16:51:13.000Z"><meta property="article:modified_time" content="2025-12-11T16:51:13.000Z"><link rel="icon" type="image/png" href="https://pic-1326566629.cos.ap-shanghai.myqcloud.com/blog/d7cfd604-0072-4fb4-8be5-8e713fa39ae6.png"><script>
        var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?a91f7c13a8a28ba871c52a11405db5fc";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
      </script><title>改变大模型自我认知 | novice.log</title><meta name="description" content="目的 使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变 启动LLaMA Factory 进入 LLaMA-Factory 目录下 使用此命令开启llamafactory，若界面关闭模型训练便会终止 若希望后台一直训练，则使用nohup 调起即可 关闭则 使用kill 指定进程名即可 若希望在使用llamafactory ..."><link rel="preload" href="/assets/style-B2LFmcfZ.css" as="style"><link rel="stylesheet" href="/assets/style-B2LFmcfZ.css"><link rel="modulepreload" href="/assets/app-D2ozI2D3.js"><link rel="modulepreload" href="/assets/index.html-Qmiq8AjE.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-d90a7a26><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-d5a8d0bc></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-d5a8d0bc> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-d90a7a26 data-v-e98a6132><div class="vp-navbar" vp-navbar data-v-e98a6132 data-v-2c31ea5e><div class="wrapper" data-v-2c31ea5e><div class="container" data-v-2c31ea5e><div class="title" data-v-2c31ea5e><div class="vp-navbar-title has-sidebar" data-v-2c31ea5e data-v-1a4f50af><a class="vp-link link no-icon title" href="/" data-v-1a4f50af><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" style="" src="https://pic-1326566629.cos.ap-shanghai.myqcloud.com/blog/d7cfd604-0072-4fb4-8be5-8e713fa39ae6.png" alt data-v-480e858a><!--]--><!--[--><img class="vp-image light logo" style="" src="https://pic-1326566629.cos.ap-shanghai.myqcloud.com/blog/d7cfd604-0072-4fb4-8be5-8e713fa39ae6.png" alt data-v-480e858a><!--]--><!--]--><!--]--><span data-v-1a4f50af>novice.log</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-2c31ea5e><div class="content-body" data-v-2c31ea5e><!--[--><!--]--><div class="vp-navbar-search search" data-v-2c31ea5e><div class="search-wrapper" data-v-97535d1e><!----><div id="local-search" data-v-97535d1e><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-97535d1e><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><!--[--><!--]--><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-2c31ea5e data-v-d43c1732><span id="main-nav-aria-label" class="visually-hidden" data-v-d43c1732>Main Navigation</span><!--[--><!--[--><a class="vp-link link navbar-menu-link" href="/" tabindex="0" data-v-d43c1732 data-v-d4acf911><!--[--><!----><span data-v-d4acf911>首页</span><!----><!--]--><!----></a><!--]--><!--[--><a class="vp-link link navbar-menu-link" href="/blog/" tabindex="0" data-v-d43c1732 data-v-d4acf911><!--[--><!----><span data-v-d4acf911>博客</span><!----><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-86530b6c><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-86530b6c><span class="text" data-v-86530b6c><!----><!----><span data-v-86530b6c>游戏攻略</span><!----><span class="vpi-chevron-down text-icon" data-v-86530b6c></span></span></button><div class="menu" data-v-86530b6c><div class="vp-menu" data-v-86530b6c data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><!----><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-1ff1855f><a class="vp-link link" href="/notes/games/hollow_knight/" data-v-1ff1855f><!--[--><!----> 空洞骑士系列 <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-86530b6c><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-86530b6c><span class="text" data-v-86530b6c><!----><!----><span data-v-86530b6c>AI大模型</span><!----><span class="vpi-chevron-down text-icon" data-v-86530b6c></span></span></button><div class="menu" data-v-86530b6c><div class="vp-menu" data-v-86530b6c data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><p class="title" data-v-c497e9e3><!----><span data-v-c497e9e3>模型部署</span></p><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-1ff1855f><a class="vp-link link" href="/vuepress-theme-plume/" data-v-1ff1855f><!--[--><!----> Ollama <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><p class="title" data-v-c497e9e3><!----><span data-v-c497e9e3>微调训练</span></p><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-1ff1855f><a class="vp-link link" href="/notes/aillm/fine-tuning/llama-factory/" data-v-1ff1855f><!--[--><!----> llama-factory <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><p class="title" data-v-c497e9e3><!----><span data-v-c497e9e3>模型应用</span></p><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-1ff1855f><a class="vp-link link" href="/vuepress-plugin/shiki/" data-v-1ff1855f><!--[--><!----> shiki <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-d43c1732 data-v-86530b6c><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-86530b6c><span class="text" data-v-86530b6c><!----><!----><span data-v-86530b6c>知识积累</span><!----><span class="vpi-chevron-down text-icon" data-v-86530b6c></span></span></button><div class="menu" data-v-86530b6c><div class="vp-menu" data-v-86530b6c data-v-709dc2b1><div class="items" data-v-709dc2b1><!--[--><!--[--><div class="vp-menu-group" data-v-709dc2b1 data-v-c497e9e3><p class="title" data-v-c497e9e3><!----><span data-v-c497e9e3>计算机</span></p><!--[--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-1ff1855f><a class="vp-link link" href="/notes/computer/computer-network/" data-v-1ff1855f><!--[--><!----> 计算机网络 <!----><!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-c497e9e3 data-v-1ff1855f><a class="vp-link link" href="/notes/computer/data-structure/" data-v-1ff1855f><!--[--><!----> 数据结构 <!----><!--]--><!----></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!--[--><!--]--><!----><div class="vp-navbar-appearance appearance" data-v-2c31ea5e data-v-a295abf6><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-a295abf6 data-v-596c25a9 data-v-7eb32327><span class="check" data-v-7eb32327><span class="icon" data-v-7eb32327><!--[--><span class="vpi-sun sun" data-v-596c25a9></span><span class="vpi-moon moon" data-v-596c25a9></span><!--]--></span></span></button></div><div class="vp-social-links vp-navbar-social-links social-links" data-v-2c31ea5e data-v-ad52545c data-v-40bac536><!--[--><a class="vp-social-link no-icon" href="https://github.com/nov1ce-lee" aria-label="github" target="_blank" rel="noopener" data-v-40bac536 data-v-67b21932><span class="vpi-social-github" /></a><!--]--></div><div class="vp-flyout vp-navbar-extra extra" data-v-2c31ea5e data-v-652282fd data-v-86530b6c><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-86530b6c><span class="vpi-more-horizontal icon" data-v-86530b6c></span></button><div class="menu" data-v-86530b6c><div class="vp-menu" data-v-86530b6c data-v-709dc2b1><!----><!--[--><!--[--><!----><div class="group" data-v-652282fd><div class="item appearance" data-v-652282fd><p class="label" data-v-652282fd>外观</p><div class="appearance-action" data-v-652282fd><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-652282fd data-v-596c25a9 data-v-7eb32327><span class="check" data-v-7eb32327><span class="icon" data-v-7eb32327><!--[--><span class="vpi-sun sun" data-v-596c25a9></span><span class="vpi-moon moon" data-v-596c25a9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-652282fd><div class="item social-links" data-v-652282fd><div class="vp-social-links social-links-list" data-v-652282fd data-v-40bac536><!--[--><a class="vp-social-link no-icon" href="https://github.com/nov1ce-lee" aria-label="github" target="_blank" rel="noopener" data-v-40bac536 data-v-67b21932><span class="vpi-social-github" /></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-2c31ea5e data-v-2b50024d><span class="container" data-v-2b50024d><span class="top" data-v-2b50024d></span><span class="middle" data-v-2b50024d></span><span class="bottom" data-v-2b50024d></span></span></button></div></div></div></div><div class="divider" data-v-2c31ea5e><div class="divider-line" data-v-2c31ea5e></div></div></div><!----></header><div class="vp-local-nav reached-top" data-v-d90a7a26 data-v-3944d8e8><button class="menu" aria-expanded="false" aria-controls="SidebarNav" data-v-3944d8e8><span class="vpi-align-left menu-icon" data-v-3944d8e8></span><span class="menu-text" data-v-3944d8e8>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-3944d8e8 data-v-4114a62c><button data-v-4114a62c>返回顶部</button><!----></div></div><aside class="vp-sidebar" vp-sidebar data-v-d90a7a26 data-v-95211354><div class="curtain" data-v-95211354></div><nav id="SidebarNav" class="nav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-95211354><span id="sidebar-aria-label" class="visually-hidden" data-v-95211354> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-473fd05b><section class="vp-sidebar-item sidebar-item level-0 collapsible has-active" data-v-473fd05b data-v-12048f0f><div class="item" role="button" tabindex="0" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><h2 class="text" data-v-12048f0f><span data-v-12048f0f>微调训练</span><!----></h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-12048f0f><span class="vpi-chevron-right caret-icon" data-v-12048f0f></span></div></div><div data-v-12048f0f data-v-12048f0f><div class="items" data-v-12048f0f><!--[--><section class="vp-sidebar-item sidebar-item level-1 collapsible has-active" data-v-12048f0f data-v-12048f0f><div class="item" role="button" tabindex="0" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><h3 class="text" data-v-12048f0f><span data-v-12048f0f>LLaMA Factory</span><!----></h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-12048f0f><span class="vpi-chevron-right caret-icon" data-v-12048f0f></span></div></div><div data-v-12048f0f data-v-12048f0f><div class="items" data-v-12048f0f><!--[--><div class="vp-sidebar-item sidebar-item level-2 is-link" data-v-12048f0f data-v-12048f0f><div class="item" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><a class="vp-link link link" href="/notes/aillm/fine-tuning/llama-factory/" data-v-12048f0f><!--[--><p class="text" data-v-12048f0f><span data-v-12048f0f>使用手册</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-2 is-link" data-v-12048f0f data-v-12048f0f><div class="item" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><a class="vp-link link link" href="/notes/aillm/fine-tuning/llama-factory/advance/" data-v-12048f0f><!--[--><p class="text" data-v-12048f0f><span data-v-12048f0f>高级用法</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-2 is-link" data-v-12048f0f data-v-12048f0f><div class="item" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><a class="vp-link link link" href="/notes/aillm/fine-tuning/process/" data-v-12048f0f><!--[--><p class="text" data-v-12048f0f><span data-v-12048f0f>模型微调常用步骤</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-2 is-link" data-v-12048f0f data-v-12048f0f><div class="item" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><a class="vp-link link link" href="/notes/aillm/fine-tuning/lammacpp/" data-v-12048f0f><!--[--><p class="text" data-v-12048f0f><span data-v-12048f0f>模型格式转换</span><!----></p><!--]--><!----></a><!----></div><!----></div><div class="vp-sidebar-item sidebar-item level-2 is-link" data-v-12048f0f data-v-12048f0f><div class="item" data-v-12048f0f><div class="indicator" data-v-12048f0f></div><!----><a class="vp-link link link" href="/notes/aillm/fine-tuning/lora/" data-v-12048f0f><!--[--><p class="text" data-v-12048f0f><span data-v-12048f0f>改变大模型自我认知</span><!----></p><!--]--><!----></a><!----></div><!----></div><!--]--></div></div></section><!--]--></div></div></section></div><!--]--><!--[--><!--]--></nav></aside><!--[--><div id="VPContent" vp-content class="vp-content has-sidebar" data-v-d90a7a26 data-v-b2beaca7><div class="vp-doc-container has-sidebar has-aside" data-v-b2beaca7 data-v-23f6ad98><!--[--><!--]--><div class="container" data-v-23f6ad98><div class="aside" vp-outline data-v-23f6ad98><div class="aside-curtain" data-v-23f6ad98></div><div class="aside-container" data-v-23f6ad98><div class="aside-content" data-v-23f6ad98><div class="vp-doc-aside" data-v-23f6ad98 data-v-5976474c><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="vp-doc-aside-outline" role="navigation" data-v-5976474c data-v-aa56eba0><div class="content" data-v-aa56eba0><div class="outline-marker" data-v-aa56eba0></div><div id="doc-outline-aria-label" aria-level="2" class="outline-title" role="heading" data-v-aa56eba0><span data-v-aa56eba0>此页内容</span><span class="vpi-print icon" data-v-aa56eba0></span></div><ul class="root" data-v-aa56eba0 data-v-3e6b023c><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-5976474c></div><!--[--><!--]--></div></div></div></div><div class="content" data-v-23f6ad98><div class="content-container" data-v-23f6ad98><!--[--><!--]--><main class="main" data-v-23f6ad98><nav class="vp-breadcrumb" data-v-23f6ad98 data-v-1ae4ad7a><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-1ae4ad7a><!--[--><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><a class="vp-link link breadcrumb" href="/" property="item" typeof="WebPage" data-v-1ae4ad7a><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-1ae4ad7a></span><meta property="name" content="首页" data-v-1ae4ad7a><meta property="position" content="1" data-v-1ae4ad7a></li><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><span class="vp-link breadcrumb" property="item" typeof="WebPage" data-v-1ae4ad7a><!--[-->微调训练<!--]--><!----></span><span class="vpi-chevron-right" data-v-1ae4ad7a></span><meta property="name" content="微调训练" data-v-1ae4ad7a><meta property="position" content="2" data-v-1ae4ad7a></li><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><span class="vp-link breadcrumb" property="item" typeof="WebPage" data-v-1ae4ad7a><!--[-->LLaMA Factory<!--]--><!----></span><span class="vpi-chevron-right" data-v-1ae4ad7a></span><meta property="name" content="LLaMA Factory" data-v-1ae4ad7a><meta property="position" content="3" data-v-1ae4ad7a></li><li property="itemListElement" typeof="ListItem" data-v-1ae4ad7a><a class="vp-link link breadcrumb current" href="/notes/aillm/fine-tuning/lora/" property="item" typeof="WebPage" data-v-1ae4ad7a><!--[-->改变大模型自我认知<!--]--><!----></a><!----><meta property="name" content="改变大模型自我认知" data-v-1ae4ad7a><meta property="position" content="4" data-v-1ae4ad7a></li><!--]--></ol></nav><!--[--><!--]--><!--[--><h1 class="vp-doc-title page-title" data-v-27be53cb>改变大模型自我认知 <!----></h1><div class="vp-doc-meta" data-v-27be53cb><!--[--><!--]--><p class="reading-time" data-v-27be53cb><span class="vpi-books icon" data-v-27be53cb></span><span data-v-27be53cb>约 2202 字</span><span data-v-27be53cb>大约 7 分钟</span></p><!----><!--[--><!--]--><p class="create-time" data-v-27be53cb><span class="vpi-clock icon" data-v-27be53cb></span><span data-v-27be53cb>2025-03-27</span></p></div><!--]--><!--[--><!--]--><div class="_notes_aillm_fine-tuning_lora_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-23f6ad98><!--[--><!--]--><div data-v-23f6ad98><h2 id="目的" tabindex="-1"><a class="header-anchor" href="#目的"><span>目的</span></a></h2><p>使用LLaMA-Factory对大模型进行微调，从而实现对大模型的自我认知的改变</p><h2 id="启动llama-factory" tabindex="-1"><a class="header-anchor" href="#启动llama-factory"><span>启动LLaMA Factory</span></a></h2><ul><li>进入 LLaMA-Factory 目录下</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">cd</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> LLaMA-Factory</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>使用此命令开启llamafactory，若界面关闭模型训练便会终止</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webui</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>若希望后台一直训练，则使用nohup 调起即可</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">nohup</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webui</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> &amp;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>关闭则 使用kill 指定进程名即可</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">kill</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -9</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>若希望在使用llamafactory 使用指定显卡，那么使用这行命令：</li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">CUDA_VISIBLE_DEVICES</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">6</span><span style="--shiki-light:#59873A;--shiki-dark:#80A665;"> llamafactory-cli</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> webui</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="模块介绍" tabindex="-1"><a class="header-anchor" href="#模块介绍"><span>模块介绍</span></a></h2><table><thead><tr><th>modules</th><th>function</th><th>note</th></tr></thead><tbody><tr><td>模型路径</td><td>支持 <code>huggingface</code> 在线路径，或者本地的模型路径</td><td>注意是绝对路径，<code>.config</code> 文件上一层</td></tr><tr><td>微调方法</td><td>支持 <code>lora / freeze / full</code> 方法</td><td><code>lora(Low-Rank Adaptation)</code>指通过在模型的某些层中添加<code>低秩矩阵</code>来实现微调<br> <code>full(Full Fine-Tuning, 全量微调)</code>指对模型的<code>所有参数</code>进行微调<br> <code>freeze(Freeze Fine-Tuning, 冻结微调)</code>指<code>冻结</code>模型的某些层或全部层，仅微调 <code>特定的参数</code></td></tr><tr><td>检查点路径</td><td>保存训练的<code>中间结果</code></td><td>此地址保存训练后的模型权重，Train 模式不需要填，会默认存入 /save文件中；其他模式填训练好的模型路径。如果训练中断，可以从检查点<code>继续训练</code></td></tr><tr><td>RoPE插值方法、加速方式</td><td>加速模型训练</td><td>一般不建议使用，会损失模型精度</td></tr><tr><td><a href="#train-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">Train</a></td><td>对模型进行训练</td><td></td></tr><tr><td><a href="#">Evaluate &amp; Predict</a></td><td>对模型进行评估、验证</td><td></td></tr><tr><td><a href="#3">Chat</a></td><td>使用模型推理</td><td></td></tr><tr><td><span class="vp-link"><!--[-->Export<!--]--><!----></span></td><td>对模型进行合并和导出</td><td></td></tr></tbody></table><h2 id="训练数据的准备" tabindex="-1"><a class="header-anchor" href="#训练数据的准备"><span>训练数据的准备</span></a></h2><h3 id="数据处理介绍" tabindex="-1"><a class="header-anchor" href="#数据处理介绍"><span>数据处理介绍</span></a></h3><p>LLaMA Factory 的数据集配置分为两步：</p><ol><li>准备数据：将训练数据存放至 <code>.json</code> 文件中，然后将训练数据上传至 <code>LLaMA-Factory</code> 的 <code>./data</code> 目录下</li><li>注册数据：配置 <code>./data</code> 中 的 <code>data_info.json</code> 文件，把训练数据路径（文件名）补充进入即可。名称可以自由命名</li></ol><div class="hint-container note"><p class="hint-container-title">注</p><p><code>LLaMA-Factory</code> 目前只支持 <code>Alpaca</code> 和 <code>ShareGPT</code> 两种数据格式，分别适用于 <code>指令监督微调</code> 和 <code>多轮对话任务</code> 。<br> 具体请查看 <a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/data_preparation.html" target="_blank" rel="noopener noreferrer">数据处理-LLaMA Factory</a></p></div><h3 id="训练数据准备" tabindex="-1"><a class="header-anchor" href="#训练数据准备"><span>训练数据准备</span></a></h3><p>使用LLaMA Factory内置的自我认知数据（/data 文件中的 <code>identity.json</code> 文件），其原始格式是这样的：</p><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-json"><span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  {</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">instruction</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">hi</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">output</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Hello! I am {{name}}, an AI assistant developed by {{author}}. How can I assist you today?</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  },</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">  ......</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  {</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">instruction</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">你好</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">output</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">您好，我是 {{name}}，一个由 {{author}} 打造的人工智能助手，请问有什么可以帮助您的吗？</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  },</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  {</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">instruction</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">你是谁</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">input</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">    &quot;</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">output</span><span style="--shiki-light:#99841877;--shiki-dark:#B8A96577;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">您好，我是由 {{author}} 发明的 {{name}}。我可以为您提供多种多样的服务，比如翻译、写代码、闲聊、为您答疑解惑等。</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">  },</span></span>
<span class="line"><span style="--shiki-light:#B31D28;--shiki-light-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic;">  ......</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>属于Alpaca 形式的 指令监督微调数据集，核心有4个键，分别对应着微调的四个指令：</p><ol><li><code>instruction</code>（必填）：明确的任务指令，模型需要根据该指令生成输出。</li><li><code>input</code>（可选）：与任务相关的背景信息或上下文。在 RAG任务中，input input参数可以用于提供检索到的外部知识或上下文信息，帮助模型生成更准确的回答</li><li><code>output</code>（必填）：模型需要生成的正确回答。</li><li><code>system</code>（可选）：系统提示词，用于定义任务的上下文。</li><li><code>history</code>（可选）：历史对话记录，用于多轮对话任务。用于控制多轮对话，指上下文信息，若无历史对话，则为[]。<br> 注：如果有多轮对话，那么history 这个list是有先后顺序的。list[0]为第一轮，list[1]为第二轮，依次向后排序，而instruction 是存放最新一轮对话信息</li></ol><h3 id="认知修改" tabindex="-1"><a class="header-anchor" href="#认知修改"><span>认知修改</span></a></h3><p>将 <code>identity.json</code> 文件中的和替换成为需要的名称信息</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">sed</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">s/{{name}}/yourModelName/g</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> identity.json</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">sed</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> -i</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">s/{{author}}/YourName/g</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> identity.json</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>因为该文件是默认内置文件，因此不需要对数据进行注册</p><h2 id="train-模型训练" tabindex="-1"><a class="header-anchor" href="#train-模型训练"><span>Train 模型训练</span></a></h2><p>训练阶段（训练方式）</p><ul><li>Supervised Fine-Tuning （监督微调）监督微调是最常见的微调方法，使用标注好的数据对预训练模型进行进一步训练，以适应特定任务（如分类、问答等）。</li><li>Reward Modeling（奖励建模）奖励建模是一种用于优化模型输出质量的方法，通常用于强化学习（RL）的上下文中。</li><li>PPO（Proximal Policy Optimization） PPO 是一种基于强化学习的微调方法，用于优化模型的输出策略。</li><li>DPO （Direct Preference Optimization）DPO 是一种基于人类偏好的直接优化方法，用于训练模型以生成更符合人类偏好的输出。 - Pre-Training（预训练）预训练是指从头开始训练一个大模型，通常使用大量的无监督数据（如文本语料库）。预训练的目标是让模型学习通用的语言知识和模式。</li></ul><p>数据路径：默认data，指的是 LLaMA-Factory 目录下的/data 相对路径。此文件夹中用于存放训练所需要的数据</p><p>数据集：支持选择多个数据集，支持预览</p><hr><p>学习率：可以不用修改</p><p>训练轮次：根据数据集大小调整，可以调的高一些，比如1000，因为可以随时停止</p><p>梯度：根据显存情况调整 最大样本数：根据数据集大小和训练需求设置。主要是防止数据量过大导致的内存溢出问题 计算类型：这里支持混合精度训练选择（fp16或 bf16）bf16的效果更佳一些。 bf16对某些架构是不支持的，和硬件有关（GPU的架构）。如果你的硬件不支持 BF16，可以选择 FP16 进行混合精度训练。 NVIDIA 4090 支持 BF16运算。我的服务器是 NVIDIA A10 GPU，是基于 Ampere 架构 的 GPU。同样也支持bf16运算。可以先选择bf16，如果不支持会报错，然后再选择fp16就行</p><blockquote><p>混合精度训练是一种结合了半精度浮点数（FP16 或 BF16）和单精度浮点数（FP32）的训练技术。其核心在于：</p><ul><li>使用 FP16 或 BF16 进行大部分计算，以减少内存占用和加速计算。</li><li>保留关键部分（如优化器参数）以 FP32 存储，以避免数值精度问题。</li><li>适用于 GPU 和支持 BF16 的硬件（如 NVIDIA Ampere 架构）</li></ul></blockquote><p>截断长度：根据任务需求/数据集配置，通常默认值为 1024 批处理大小 验证集比例</p><p>其他参数：</p><p>日志间隔：多久输出日志信息 保存问题：多久保存权重</p><p>LoRA参数设置 LoRA秩：LoRA秩越大模型越大，默认秩是8 参数配置好后，点击开始，即可进行训练。</p><p>通过命令行开始训练 预览命令</p><p>输出目录：模型训练结果的保存位置，默认是/saves文件</p><p>训练时会实时显示损失变化。</p><p>设备数量（和服务器的实际情况有关），若有多张卡，就可以使用DeepSpeed进行训练的加速。若只有1张卡那么就不要使用DeepSpeed，否则会造成显存占比过高，效果反而会变差。</p><p>Num example指训练数据有多少条样本 Num epoch 指我们配置的epoch ，要训练多少轮次 total training batch size=80 计算出的整体训练批次 （基于输入长度计算得到） Total optimization steps ：计算出来的要跑的epoch { loss:xxx , learning_rate : xxx ,epoch:0.5 } 此处的epoch指是 epoch 表示当前训练进度相对于整个数据集的比例.。 作用：帮助开发者了解训练进度。例如，如果总 epoch 是 10，epoch: 0.5 表示模型已经完成了 5% 的总训练进度。</p><p>输出文件结构 模型训练好后，会保存至 LLaMA-Factory 的 /saves文件中</p><p>路径：/saves/基座模型名称/微调方法</p><p>由于保存间隔设置的100，因此每100个步长保存一次模型的权重</p><p>我们看下checkpoint-800文件，下图红框圈出来部分为lora 模型，其中</p><p>traning_args.yaml 文件为模型训练的参数信息</p><p>save_steps 为模型训练的步长 output_dir 为模型保存路径</p><p>adapter_config.json为lora的参数信息</p><p>beft_type(微调方法)：LORA base_model_name_or_path： 基座模型 task_type：任务类型，生成式模型 CAUSAL_LM adapter_model.safetensors：模型权重文件 trainer_state.json：模型训练状态文件</p><p>epoch：训练轮次 eval_steps：基于验证集的比例得到的，每隔多少个步长会做一次验证 global_step：本次步长是多少 log_history：历史轮次的学习率、loss、步长等信息</p><p>整体训练完后，会保存training的LOSS和eval的LOSS 图</p></div><!----><!----><!----></div></main><footer class="vp-doc-footer" data-v-23f6ad98 data-v-fda6bbae><!--[--><!--]--><!----><div class="contributors" aria-label="Contributors" data-v-fda6bbae><span class="contributors-label" data-v-fda6bbae>贡献者: </span><span class="contributors-info" data-v-fda6bbae><!--[--><!--[--><span class="contributor" data-v-fda6bbae>nov1ce</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-fda6bbae><div class="pager" data-v-fda6bbae><a class="vp-link link pager-link prev" href="/notes/aillm/fine-tuning/lammacpp/" data-v-fda6bbae><!--[--><span class="desc" data-v-fda6bbae>上一页</span><span class="title" data-v-fda6bbae>模型格式转换</span><!--]--><!----></a></div><div class="pager" data-v-fda6bbae><!----></div></nav></footer><!----><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-d90a7a26 data-v-bcf8d9a6><span class="percent" data-allow-mismatch data-v-bcf8d9a6>0%</span><span class="show icon vpi-back-to-top" data-v-bcf8d9a6></span><svg aria-hidden="true" data-v-bcf8d9a6><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-bcf8d9a6></circle></svg></button><footer class="vp-footer has-sidebar" vp-footer data-v-d90a7a26 data-v-400675cf><!--[--><div class="container" data-v-400675cf><p class="message" data-v-400675cf>Power by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-400675cf> © 2023-2025 novice.log | novice :) </p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-D2ozI2D3.js" defer></script></body></html>